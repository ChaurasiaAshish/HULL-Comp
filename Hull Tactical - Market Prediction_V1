{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ashish090/hull-tactical-market-prediction-v1?scriptVersionId=276132997\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"c2278a86","metadata":{"execution":{"iopub.execute_input":"2025-11-11T16:23:16.164531Z","iopub.status.busy":"2025-11-11T16:23:16.164114Z","iopub.status.idle":"2025-11-11T16:23:28.76753Z","shell.execute_reply":"2025-11-11T16:23:28.766486Z"},"papermill":{"duration":12.608799,"end_time":"2025-11-11T16:23:28.769257","exception":false,"start_time":"2025-11-11T16:23:16.160458","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005606 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 21576\n","[LightGBM] [Info] Number of data points in the train set: 9021, number of used features: 94\n","[LightGBM] [Info] Start training from score 0.000053\n","Running local gateway test...\n"]}],"source":["# Hull Tactical Market Prediction - Updated Submission Notebook\n","# Paste this into a Kaggle notebook, disable Internet, Save & Run All (Commit), then Submit.\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import lightgbm as lgb\n","from scipy.optimize import minimize, Bounds\n","\n","# --- Paths ---\n","TRAIN_PATH = \"/kaggle/input/hull-tactical-market-prediction/train.csv\"\n","TEST_PATH = \"/kaggle/input/hull-tactical-market-prediction/test.csv\"\n","\n","# --- Load data (if available in environment) ---\n","train_df = None\n","test_df = None\n","if os.path.exists(TRAIN_PATH):\n","    train_df = pd.read_csv(TRAIN_PATH, index_col=\"date_id\")\n","if os.path.exists(TEST_PATH):\n","    test_df = pd.read_csv(TEST_PATH)\n","\n","# --- Feature selection: shared features between train and test (exclude targets/metadata) ---\n","excluded_cols = {\n","    'market_forward_excess_returns', 'forward_returns', 'risk_free_rate',\n","    'lagged_forward_returns', 'lagged_risk_free_rate', 'lagged_market_forward_excess_returns',\n","    'is_scored', 'date_id'\n","}\n","shared_features = []\n","if train_df is not None and test_df is not None:\n","    # Use columns that are present in both and not excluded\n","    shared_features = [c for c in train_df.columns if c in test_df.columns and c not in excluded_cols]\n","\n","# --- Baseline strategy ---\n","def predict_baseline(_):\n","    \"\"\"Constant allocation baseline.\"\"\"\n","    return 0.806\n","\n","# --- LightGBM model utilities ---\n","MODEL_FILE = \"lgbm_model.txt\"\n","lgbm_model = None\n","\n","def train_lgbm_model(features):\n","    \"\"\"Train a simple LightGBM model on train_df using the provided features.\"\"\"\n","    global lgbm_model\n","    if train_df is None:\n","        raise RuntimeError(\"Training data not available to train model.\")\n","    X = train_df[features].fillna(0.0)\n","    y = train_df['market_forward_excess_returns']\n","    model = lgb.LGBMRegressor(\n","        objective='regression',\n","        n_estimators=200,\n","        learning_rate=0.05,\n","        num_leaves=31,\n","        random_state=42,\n","        n_jobs=-1\n","    )\n","    model.fit(X, y)\n","    # Save text model for inference run\n","    model.booster_.save_model(MODEL_FILE)\n","    lgbm_model = lgb.Booster(model_file=MODEL_FILE)\n","    return lgbm_model\n","\n","def load_lgbm_model():\n","    global lgbm_model\n","    if os.path.exists(MODEL_FILE):\n","        lgbm_model = lgb.Booster(model_file=MODEL_FILE)\n","    return lgbm_model\n","\n","# --- Oracle strategy (educational only) ---\n","optimal_oracle_preds = None\n","oracle_counter = 0\n","\n","def calculate_oracle_predictions():\n","    global optimal_oracle_preds\n","    if train_df is None or 'forward_returns' not in train_df.columns:\n","        optimal_oracle_preds = None\n","        return\n","    recent = train_df.tail(180).copy()\n","    def adjusted_sharpe(x):\n","        preds = np.clip(x, 0, 2)\n","        returns = recent['forward_returns'].values * preds\n","        return returns.mean() / returns.std() if returns.std() > 0 else 0\n","    def objective(x):\n","        return -adjusted_sharpe(x)\n","    x0 = np.full(len(recent), 0.8)\n","    bounds = Bounds(np.zeros(len(recent)), np.full(len(recent), 2.0))\n","    res = minimize(objective, x0, method=\"Powell\", bounds=bounds, tol=1e-6)\n","    optimal_oracle_preds = np.clip(res.x, 0, 2)\n","\n","def predict_oracle(_):\n","    global oracle_counter\n","    if optimal_oracle_preds is None or oracle_counter >= len(optimal_oracle_preds):\n","        return 0.0\n","    val = float(optimal_oracle_preds[oracle_counter])\n","    oracle_counter += 1\n","    return val\n","\n","# --- Strategy selection (choose one) ---\n","# Options: \"baseline\", \"lgbm\", \"oracle\"\n","strategy = \"lgbm\"\n","\n","# Prepare model if using lgbm\n","if strategy == \"lgbm\":\n","    # If model file exists load it; otherwise train if data available\n","    if os.path.exists(MODEL_FILE):\n","        try:\n","            load_lgbm_model()\n","        except Exception:\n","            # If loading fails, try training (if data present)\n","            if train_df is not None and len(shared_features) > 0:\n","                train_lgbm_model(shared_features)\n","    else:\n","        if train_df is not None and len(shared_features) > 0:\n","            train_lgbm_model(shared_features)\n","\n","if strategy == \"oracle\":\n","    calculate_oracle_predictions()\n","\n","# --- Robust predict wrapper (submission entrypoint) ---\n","# Accepts polars.DataFrame or pandas.DataFrame or dict-like single row and returns float\n","try:\n","    import polars as pl\n","except Exception:\n","    pl = None\n","\n","def _to_pandas_safe(batch):\n","    \"\"\"Convert incoming batch (polars/pandas/dict) to a pandas DataFrame single-row copy.\"\"\"\n","    if pl is not None and isinstance(batch, pl.DataFrame):\n","        df = batch.to_pandas()\n","        return df.copy()\n","    if isinstance(batch, pd.DataFrame):\n","        return batch.copy()\n","    if isinstance(batch, dict):\n","        return pd.DataFrame([batch])\n","    # Try to coerce generic input\n","    try:\n","        return pd.DataFrame(batch)\n","    except Exception:\n","        raise ValueError(\"Unsupported batch type for predict\")\n","\n","def predict(batch) -> float:\n","    \"\"\"\n","    Top-level predict function expected by the evaluation server.\n","    Returns a float allocation in [0, 2].\n","    \"\"\"\n","    # Coerce to pandas DataFrame and keep only first row (server passes one row)\n","    test_df_local = _to_pandas_safe(batch)\n","    if len(test_df_local) > 1:\n","        test_df_local = test_df_local.iloc[[0]].reset_index(drop=True)\n","\n","    # Ensure shared features exist; fill missing columns with zeros\n","    if len(shared_features) == 0:\n","        # If shared_features wasn't computed (e.g., missing data files), fallback to baseline\n","        return float(predict_baseline(test_df_local))\n","\n","    for f in shared_features:\n","        if f not in test_df_local.columns:\n","            test_df_local[f] = 0.0\n","\n","    # Strategy dispatch\n","    if strategy == \"lgbm\":\n","        # Ensure model is loaded; otherwise fallback to baseline\n","        global lgbm_model\n","        if lgbm_model is None:\n","            if os.path.exists(MODEL_FILE):\n","                try:\n","                    load_lgbm_model()\n","                except Exception:\n","                    return float(predict_baseline(test_df_local))\n","            else:\n","                return float(predict_baseline(test_df_local))\n","        # Prepare features and predict\n","        X = test_df_local[shared_features].fillna(0.0)\n","        try:\n","            pred_arr = lgbm_model.predict(X.values)\n","            pred = float(pred_arr[0]) if hasattr(pred_arr, \"__len__\") else float(pred_arr)\n","        except Exception:\n","            return float(predict_baseline(test_df_local))\n","        # Map raw prediction to allocation and clip to [0,2]\n","        allocation = 0.8 + 50.0 * pred\n","        allocation = float(np.clip(allocation, 0.0, 2.0))\n","        return allocation\n","\n","    elif strategy == \"oracle\":\n","        return float(predict_oracle(test_df_local))\n","\n","    else:\n","        return float(predict_baseline(test_df_local))\n","\n","# --- Wire inference server ---\n","# This is the correct way to start the server for submission\n","# and run a local test.\n","\n","# We must import the server and os\n","try:\n","    import kaggle_evaluation\n","    import kaggle_evaluation.default_inference_server  # <--- ADD THIS LINE\n","except ImportError:\n","    # Handle the case where the package is not installed (e.g., local environment)\n","    print(\"kaggle_evaluation package not found. Skipping server setup.\")\n","    inference_server = None\n","else:\n","    # Create the server object\n","    inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n","    \n","    # Check if we are in the Kaggle submission environment\n","    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n","        # This is the submission run: start the server to listen for requests\n","        print(\"Starting inference server...\")\n","        inference_server.serve()\n","    else:\n","        # This is the interactive/commit run: run the local gateway for testing\n","        print(\"Running local gateway test...\")\n","        # Make sure the path points to your input data directory\n","        local_gateway_path = '/kaggle/input/hull-tactical-market-prediction/'\n","        if os.path.exists(local_gateway_path):\n","            inference_server.run_local_gateway((local_gateway_path,))\n","        else:\n","            print(\"Local gateway path not found. Skipping local test.\")\n","            # You can fall back to your original __main__ test if you prefer\n","            if test_df is not None and len(test_df) > 0:\n","                print(\"Running simple local test:\")\n","                sample = test_df.iloc[[0]].copy()\n","                print(\"Sample allocation:\", predict(sample))\n","            else:\n","                print(\"Skipping simple local test: test_df not available.\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":14348714,"sourceId":111543,"sourceType":"competition"}],"dockerImageVersionId":31192,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":18.092898,"end_time":"2025-11-11T16:23:29.69157","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-11T16:23:11.598672","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}